tensor flow

do the gpu part later. Gotta check if I have it on linux or windows

https://www.tensorflow.org/install/install_linux#InstallingAnaconda
do all the stuff. used python 3.6.1

aww no it didn't run probably should check the nvidia stuff since I installed the gpu one.
yay run this program to test:
# Python
import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session()
print(sess.run(hello))

From chapter 2, ESL

KNN
find k observations with xi closest to x
how to choose k?
    increasing k means less variance, more bias
distance can be measured in euclidean, manhattan, hamming graph theory or other math stuff

It then estimates the conditional probability for each class, that is, the fraction of points in A with that given class label. 

then input x gets assigned to the class with the largest probability.


that's a good description without the maths
except how does it estimate prob? Something to do with an indicator function indicating if in set X subset A in X is all 1, anything not A in X is 0... 
https://www.statlect.com/fundamentals-of-probability/indicator-functions

Least Squares:
assumes that linear fit is good
    low variance, high bias

loss functons L(Y, f(X)) penalize errors in predictions

common to use Y - f(X)^2

normalization resources:
http://scikit-learn.org/stable/modules/preprocessing.html
http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html

beautiful soup is used to read html for data scraping
Mechanize also useful

what you do for the training set e.g., normalize, you must do to the test set (normalize with numbers used to normalize training set)


clustering: unsupervised. Picking class labels when labels are not known
classificiation: supervised
semi-supervised: data set where you have some labeled data, mostly not

what did we do today?
learn that there are a bunch of measures of how well your model is doing

knn:
    find nearest neighors
    compare neighbors to known labels 
kmeans:
    choose centroids
    assign clusters based on centroids
    move centroid to average point of each cluster
    repeat until convergence
    diff between initializations and iterations


what am I confused about?
scoring models
cross validation and scoring based on that and all the types of scorings as mentioned above

adjusted rand score:
http://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html

The Rand Index computes a similarity measure between two clusterings by considering all pairs of samples and counting pairs that are assigned in the same or different clusters in the predicted and true clusterings.

note:
In machine learning, a hyperparameter is a parameter whose value is set before the learning process begins. By contrast, the values of other parameters are derived via training.

resources for week 10

http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html
scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html

