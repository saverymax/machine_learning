{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 7\n",
    "## Linear regression.\n",
    "  \n",
    "  \n",
    "Ayal Gussow, 03/15/2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's have a look at *Ames* housing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Id</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>missing_second_floor</th>\n",
       "      <th>total_sf</th>\n",
       "      <th>normalized_total_sf</th>\n",
       "      <th>CentralAir_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>854.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>208500</td>\n",
       "      <td>False</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>0.681956</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>181500</td>\n",
       "      <td>False</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>-0.362473</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>920</td>\n",
       "      <td>866.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>223500</td>\n",
       "      <td>False</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>0.859135</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>961</td>\n",
       "      <td>756.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>140000</td>\n",
       "      <td>False</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>0.698275</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>250000</td>\n",
       "      <td>False</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>1.819637</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  1stFlrSF  2ndFlrSF CentralAir  Id  LotFrontage SaleCondition  \\\n",
       "0           0       856     854.0          Y   1         65.0        normal   \n",
       "1           1      1262       0.0          Y   2         80.0        normal   \n",
       "2           2       920     866.0          Y   3         68.0        normal   \n",
       "3           3       961     756.0          Y   4         60.0      abnormal   \n",
       "4           4      1145    1053.0          Y   5         84.0        normal   \n",
       "\n",
       "   SalePrice  missing_second_floor  total_sf  normalized_total_sf  \\\n",
       "0     208500                 False    1710.0             0.681956   \n",
       "1     181500                 False    1262.0            -0.362473   \n",
       "2     223500                 False    1786.0             0.859135   \n",
       "3     140000                 False    1717.0             0.698275   \n",
       "4     250000                 False    2198.0             1.819637   \n",
       "\n",
       "   CentralAir_bool  \n",
       "0             True  \n",
       "1             True  \n",
       "2             True  \n",
       "3             True  \n",
       "4             True  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ames = pd.read_table(\"preprocessed_ames.csv\", sep=\",\")\n",
    "ames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37    153000\n",
       "40    160000\n",
       "0     208500\n",
       "33    165500\n",
       "17     90000\n",
       "34    277500\n",
       "21    139400\n",
       "44    141000\n",
       "30     40000\n",
       "24    154000\n",
       "Name: SalePrice, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Focus on features, outcome\n",
    "X = ames[[\"LotFrontage\", \"total_sf\"]]\n",
    "y = ames.SalePrice\n",
    "\n",
    "#X.head()\n",
    "#y.head()\n",
    "\n",
    "# Let's divide this data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=213\n",
    ")\n",
    "\n",
    "X_train\n",
    "X_test\n",
    "y_train\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sklearn makes life easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-45958.8156414 [ 884.40517516  116.26475214]\n",
      "[ 170282.55084091  182265.75090014  210340.24689683  213599.62525124\n",
      "  168397.47573846  188594.77295274  133273.6247095   177173.60802377\n",
      "  151382.12167991  142378.69727861]\n",
      "170282.55084090805\t153000\t17283.0\n",
      "182265.750900142\t160000\t22266.0\n",
      "210340.2468968307\t208500\t1840.0\n",
      "213599.62525124307\t165500\t48100.0\n",
      "168397.4757384613\t90000\t78397.0\n",
      "188594.77295273604\t277500\t88905.0\n",
      "133273.62470949627\t139400\t6126.0\n",
      "177173.60802377484\t141000\t36174.0\n",
      "151382.1216799105\t40000\t111382.0\n",
      "142378.69727860682\t154000\t11621.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#print(X_train.head())\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train) # train\n",
    "print(lr.intercept_, lr.coef_)\n",
    "preds = lr.predict(X_test) #predict\n",
    "\n",
    "# Assessments\n",
    "print(preds)\n",
    "print(\"\\n\".join([\"{}\\t{}\\t{}\".format(pred, truth, round(abs(pred-truth))) for pred, truth in zip(preds, y_test)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluating Metric and Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2603c38a90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMYlyYS0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f260781d6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's get the RMSE\n",
    "#print(np.sqrt(mean_squared_error(preds, y_test)))\n",
    "\n",
    "#plt.scatter(y_test, preds)\n",
    "\n",
    "#print(lr.coef_)\n",
    "X_train.columns\n",
    "X_train.LotFrontage.hist()\n",
    "X_train.total_sf.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Preprocessing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 884.40517516  116.26475214]\n",
      "[ 16067.84756897  54808.49074935]\n",
      "[ 170282.55084091  182265.75090014  210340.24689683  213599.62525124\n",
      "  168397.47573846  188594.77295274  133273.6247095   177173.60802377\n",
      "  151382.12167991  142378.69727861]\n",
      "[ 170282.55084091  182265.75090014  210340.24689683  213599.62525124\n",
      "  168397.47573846  188594.77295274  133273.6247095   177173.60802377\n",
      "  151382.12167991  142378.69727861]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#standard_scaler = preprocessing.StandardScaler()\n",
    "#scaler = standard_scaler.fit(X_train)\n",
    "#print(scaler.mean_)\n",
    "#print(X_train.mean())\n",
    "\n",
    "#print(scaler.var_)\n",
    "#print(X_train.var(ddof=0))\n",
    "scaled_features = scaler.transform(X_train)\n",
    "X_train_nrm = pd.DataFrame(scaled_features, index=X_train.index, columns=X_train.columns)\n",
    "#print(X_train_nrm.mean())\n",
    "#print(X_train_nrm.var(ddof=0))\n",
    "\n",
    "lr_nrm = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lr_nrm.fit(X_train_nrm, y_train)\n",
    "\n",
    "# Test the model\n",
    "X_test_nrm = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    index=X_test.index, columns=X_test.columns\n",
    ")\n",
    "\n",
    "#print(X_test_nrm.mean(), \"X_test mean\")\n",
    "preds_nrm = lr_nrm.predict(X_test_nrm)\n",
    "print(lr.coef_)\n",
    "print(lr_nrm.coef_)\n",
    "\n",
    "#np.isclose(preds, preds_nrm)\n",
    "print(preds)\n",
    "print(preds_nrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Manually, in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-45958.81564144    884.40517516    116.26475214]\n",
      "-45958.8156414 [ 884.40517516  116.26475214]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = X_train.shape\n",
    "\n",
    "# Add an \"intercept\" term for beta_0\n",
    "intercept_x = np.hstack((np.ones((n,1)), X_train))\n",
    "#print(intercept_x)\n",
    "\n",
    "solution, sum_of_square_residuals, rank, singvals = np.linalg.lstsq(intercept_x, y_train)\n",
    "print(solution)\n",
    "print(lr.intercept_, lr.coef_)\n",
    "\n",
    "preds_man = solution[0] * 1 + solution[1] * X_test.iloc[:, 0] + solution[2] * X_test.iloc[:, 1]\n",
    "np.isclose(preds, preds_man)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$ y = \\beta_0 + \\beta_1 * x_1 + \\beta_2 * x_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some Notes\n",
    "* Gradient Descent (stochastic)\n",
    "* \"Linear\" in linear model: linear combination of input, weights, i.e. $y = \\beta X$\n",
    "* Overcomplex models (m>>n) tend to overfit\n",
    "* Some forms of linear regression penalize for complexity\n",
    "* **Categorical Variables**: http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some notes on model complexity\n",
    "* Very simple models **underfit**, leads to high **bias**\n",
    "* Very complex models **overfit**, leads to high **variance**\n",
    "* The goal is to differentiate the **signal** from the **noise**\n",
    "* (Highly recommended book on predictions: http://amzn.to/2DuydQ2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to try and overcome these issues\n",
    "* **Never train and evaluate on the same set!**\n",
    "* We measure the performance of our model on the test set.\n",
    "* Validation curves (http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Most important\n",
    "* Guiding questions: What are the data saying?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "livereveal": {
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
